{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkkYzNBtM6sBtbn5bKXuyH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlibeisel/mason_water_budget/blob/main/reach_precip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By Carli Beisel\n",
        "\n",
        "Created August, 2024\n",
        "\n",
        "Purpose: Calculates precipitation for each Reach within Mason Drainage from Daymet."
      ],
      "metadata": {
        "id": "8GUeFQqUDkGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Install packages and connect to Google Drive"
      ],
      "metadata": {
        "id": "Xbg3kacdDyh0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aH3Bgqo6M1di"
      },
      "outputs": [],
      "source": [
        "# Installs geemap package\n",
        "import subprocess\n",
        "!pip install geemap\n",
        "\n",
        "try:\n",
        "    import geemap\n",
        "except ImportError:\n",
        "    print('geemap package not installed. Installing ...')\n",
        "    subprocess.check_call([\"python\", '-m', 'pip', 'install', 'geemap'])\n",
        "\n",
        "# Checks whether this notebook is running on Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    import geemap.eefolium as emap\n",
        "except:\n",
        "    import geemap as emap\n",
        "\n",
        "# Authenticates and initializes Earth Engine\n",
        "import ee\n",
        "\n",
        "try:\n",
        "    ee.Initialize()\n",
        "except Exception as e:\n",
        "    ee.Authenticate()\n",
        "    ee.Initialize(project = 'extract-gridmet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geopandas\n",
        "import geopandas as gpd #import independent shapefile\n",
        "import json #for metadata of shapefile\n",
        "import os #for file paths\n",
        "import numpy as np #for stats and arrays\n",
        "import pandas as pd #for dataframes\n",
        "!pip install pycrs\n",
        "import pycrs\n",
        "\n",
        "#Connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mlxojYxID2NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Import reach shapefiles and start/end dates to clip to dataset"
      ],
      "metadata": {
        "id": "7tFMnYzXD_DH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ------------------------------------------------------- ##\n",
        "##   Import shapefile and start/end dates to clip dataset  ##\n",
        "## ------------------------------------------------------- ##\n",
        "start_end = pd.read_csv('/content/drive/MyDrive/Data/Drains_Lower_Boise_River/data_input/start_end_dates.csv')\n",
        "shp_file = '/content/drive/MyDrive/Data/Drains_Lower_Boise_River/data_input/drain_delineation/Drains_Merge_07072022.shp'\n",
        "subset = emap.shp_to_ee(shp_file) # converts shapefile to feature in GEE\n",
        "\n",
        "map = emap.Map(center=(43.6150, -116.2023),zoom=8)\n",
        "map.addLayer(ee.Image().paint(subset, 0, 2), {}, 'POU')\n",
        "map.addLayerControl()\n",
        "map"
      ],
      "metadata": {
        "id": "Ox0ivEw2D9Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ------------------------------------ ##\n",
        "##        REACH PRECIPITATION           ##\n",
        "## ------------------------------------ ##\n",
        "\n",
        "# NOTE: wy = Water Year: October 1 - September 30\n",
        "\n",
        "# CHANGE TO DAILY SUM!\n",
        "years = np.arange(1987,2021)\n",
        "wy_pr = []\n",
        "\n",
        "for i in range(len(start_end)):\n",
        "  daymet = ee.ImageCollection(\"NASA/ORNL/DAYMET_V4\").filterDate((str(years[i]-1)+'-10-01'), (str(years[i])+'-9-30')) #get image collection for water year\n",
        "  pr = daymet.select('prcp').map(lambda image: image.clip(subset)).sum().set({'system:index': str(start_end['Year'][i])}) #select precip to analyze and sum\n",
        "  wy_pr.append(pr)\n",
        "\n",
        "wy_pr = ee.ImageCollection(wy_pr)"
      ],
      "metadata": {
        "id": "U0ZfmqNAEDq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ------------------------ ##\n",
        "##   CALCULATE ZONAL STATS  ##\n",
        "## ------------------------ ##\n",
        "\n",
        "# Change to daily sum!\n",
        "\n",
        "out_stats = os.path.join('/content/drive/MyDrive/Data/Drains_Lower_Boise_River/data_output/climate_data_extract_out/wy_precip_stats.csv')\n",
        "emap.zonal_statistics(wy_pr, subset, out_stats, statistics_type='MEAN', scale=1000)"
      ],
      "metadata": {
        "id": "W9s9lSWJEQ5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ---------------------------------------------- ##\n",
        "##   CREATE CLIMATE STAT FOR EACH POU AND EXPORT  ##\n",
        "## ---------------------------------------------- ##\n",
        "\n",
        "# delete excess and make for each reach\n",
        "\n",
        "years = np.arange(1987,2021)\n",
        "wy_precip = pd.read_csv('/content/drive/MyDrive/Data/Drains_Lower_Boise_River/data_output/climate_data_extract_out/wy_precip_stats.csv')\n",
        "ant_precip = pd.read_csv('/content/drive/MyDrive/Data/Drains_Lower_Boise_River/data_output/climate_data_extract_out/ant_precip_stats.csv')\n",
        "JA_temp = pd.read_csv('/content/drive/MyDrive/Data/Drains_Lower_Boise_River/data_output/climate_data_extract_out/JAtemp_stats.csv')\n",
        "irrig_temp = pd.read_csv('/content/drive/MyDrive/Data/Drains_Lower_Boise_River/data_output/climate_data_extract_out/ir_tmp_stats.csv')\n",
        "et_irrig = pd.read_csv('/content/drive/MyDrive/Data/Drains_Lower_Boise_River/data_output/climate_data_extract_out/et.csv')\n",
        "\n",
        "\n",
        "names = et_irrig['Name']\n",
        "\n",
        "for i in range(len(names)):\n",
        "  df = pd.DataFrame(years, columns=['Year'])\n",
        "  df['NAME'] = names[i]\n",
        "  df['ant_prcp'] = ant_precip.iloc[i,0:34].values\n",
        "  df['wy_prcp'] = wy_precip.iloc[i,0:34].values\n",
        "  df['irrig_temp'] = irrig_temp.iloc[i,0:34].values\n",
        "  df['JuneAug_temp'] = JA_temp.iloc[i,0:34].values\n",
        "  df['et'] = et_irrig.iloc[i,0:34].values\n",
        "  out_path = os.path.join('/content/drive/MyDrive/Data/Drains_Lower_Boise_River/data_output/climate_data_extract_out/final/'+names[i]+'_climate.csv')\n",
        "  df.to_csv(out_path)"
      ],
      "metadata": {
        "id": "0SAVblFAEUfv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}